{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb21cfa",
   "metadata": {},
   "source": [
    "\n",
    "# Automated Slide Generation from Research Papers\n",
    "*Final Study Project Notebook*\n",
    "\n",
    "**Goal:** Automatically generate PowerPoint slides from research papers using the arXiv dataset, local NLP models, and Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6761ba6",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ec7185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "import re\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6ccbc",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fbb358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 arXiv articles, 1000 PubMed articles.\n",
      "Combined dataset size: 2000\n",
      "arXiv sample keys: dict_keys(['article_id', 'article_text', 'abstract_text', 'labels', 'section_names', 'sections', 'source'])\n",
      "arXiv sample (article_text): additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models .\n",
      "arXiv sample (abstract_text): <S> additive models play an important role in semiparametric statistics . </S> <S> this paper gives learning rates for regularized kernel based methods for additive models . </S> <S> these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . </S> <S> additionally , \n",
      "\n",
      "PubMed sample keys: dict_keys(['article_id', 'article_text', 'abstract_text', 'labels', 'section_names', 'sections', 'source'])\n",
      "PubMed sample (article_text): a recent systematic analysis showed that in 2011 , 314 ( 296 - 331 ) million children younger than 5 years were mildly , moderately or severely stunted and 258 ( 240 - 274 ) million were mildly , moderately or severely underweight in the developing countries . in iran a study among 752 high school girls in sistan and baluchestan showed prevalence of 16.2% , 8.6% and 1.5% , for underweight , overweight and obesity , respectively . the prevalence of malnutrition among elementary school aged childr\n",
      "PubMed sample (abstract_text): <S> background : the present study was carried out to assess the effects of community nutrition intervention based on advocacy approach on malnutrition status among school - aged children in shiraz , iran.materials and methods : this case - control nutritional intervention has been done between 2008 and 2009 on 2897 primary and secondary school boys and girls ( 7 - 13 years old ) based on advocacy approach in shiraz , iran . </S> <S> the project provided nutritious snacks in public schools over \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl_lines(filepath, n=None, source_name=None):\n",
    "    \"\"\"Load up to n lines from a .txt file (JSON objects per line). If n=None, load all.\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if n is not None and i >= n:\n",
    "                break\n",
    "            item = json.loads(line.strip())\n",
    "            if source_name:\n",
    "                item['source'] = source_name\n",
    "            data.append(item)\n",
    "    return data\n",
    "\n",
    "# Paths for both datasets\n",
    "ARXIV_PATH = r\"C:/Users/amira/Downloads/datasets SlidegenAI/arxiv-dataset/arxiv-dataset/train.txt\"\n",
    "PUBMED_PATH = r\"C:/Users/amira/Downloads/datasets SlidegenAI/pubmed-dataset/pubmed-dataset/train.txt\"\n",
    "\n",
    "# Load data (set n=None to load all, or choose a fixed n for each)\n",
    "arxiv_samples = load_jsonl_lines(ARXIV_PATH, n=1000, source_name=\"arxiv\")\n",
    "pubmed_samples = load_jsonl_lines(PUBMED_PATH, n=1000, source_name=\"pubmed\")\n",
    "\n",
    "# Combine into one dataset\n",
    "combined_samples = arxiv_samples + pubmed_samples\n",
    "\n",
    "print(f\"Loaded {len(arxiv_samples)} arXiv articles, {len(pubmed_samples)} PubMed articles.\")\n",
    "print(f\"Combined dataset size: {len(combined_samples)}\")\n",
    "\n",
    "# Preview samples as text\n",
    "def preview(sample, name):\n",
    "    print(f\"{name} sample keys: {sample.keys()}\")\n",
    "    print(f\"{name} sample (article_text):\", \" \".join(sample['article_text'])[:500])\n",
    "    print(f\"{name} sample (abstract_text):\", \" \".join(sample['abstract_text'])[:500])\n",
    "\n",
    "preview(arxiv_samples[0], \"arXiv\")\n",
    "print()\n",
    "preview(pubmed_samples[0], \"PubMed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b96681",
   "metadata": {},
   "source": [
    "## 3. Article Section Splitting (Heuristic)\n",
    "\n",
    "This cell will process all 2000 articles (or however many you have in combined_samples).\n",
    "\n",
    "The tqdm library gives you a progress bar in the notebook—if you don’t have it, run pip install tqdm.\n",
    "\n",
    "The result, all_sections, is a list of dictionaries—each with article metadata, abstract, and a list of (section_title, section_text) tuples.\n",
    "\n",
    "Handles any errors, skipping problematic articles but keeping their abstracts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4611e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2000 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 33540.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process article_id PMC4227732: list index out of range\n",
      "Processed 2000 articles.\n",
      "Example (first article):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm  # for a progress bar\n",
    "\n",
    "def split_sections(text):\n",
    "    \"\"\"\n",
    "    Split article into sections using common section headers.\n",
    "    Returns a list of (section_title, section_text) tuples.\n",
    "    \"\"\"\n",
    "    headers = [\n",
    "        r'\\n\\s*abstract\\s*\\n',\n",
    "        r'\\n\\s*introduction\\s*\\n',\n",
    "        r'\\n\\s*related work[s]?\\s*\\n',\n",
    "        r'\\n\\s*method[s]?(ology)?\\s*\\n',\n",
    "        r'\\n\\s*experiment[s]?\\s*\\n',\n",
    "        r'\\n\\s*results\\s*\\n',\n",
    "        r'\\n\\s*discussion[s]?\\s*\\n',\n",
    "        r'\\n\\s*conclusion[s]?\\s*\\n',\n",
    "        r'\\n\\s*references\\s*\\n'\n",
    "    ]\n",
    "    pattern = \"|\".join(headers)\n",
    "    splits = re.split(pattern, text, flags=re.IGNORECASE)\n",
    "    headers_found = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "    sections = []\n",
    "    for idx, content in enumerate(splits[1:]):  # First split is before first header\n",
    "        sec_title = re.sub(r'\\W+', ' ', headers_found[idx]).strip().title()\n",
    "        sec_content = content.strip()\n",
    "        if len(sec_content) > 100:  # Skip empty/very short sections\n",
    "            sections.append((sec_title, sec_content))\n",
    "    return sections\n",
    "\n",
    "all_sections = []\n",
    "print(f\"Processing {len(combined_samples)} articles...\")\n",
    "\n",
    "for sample in tqdm(combined_samples):\n",
    "    full_article_text = \" \".join(sample['article_text'])\n",
    "    try:\n",
    "        sections = split_sections(full_article_text)\n",
    "        all_sections.append({\n",
    "            \"article_id\": sample.get('article_id'),\n",
    "            \"source\": sample.get('source'),\n",
    "            \"sections\": sections,\n",
    "            \"abstract\": \" \".join(sample['abstract_text'])\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process article_id {sample.get('article_id')}: {e}\")\n",
    "        all_sections.append({\n",
    "            \"article_id\": sample.get('article_id'),\n",
    "            \"source\": sample.get('source'),\n",
    "            \"sections\": [],\n",
    "            \"abstract\": \" \".join(sample['abstract_text'])\n",
    "        })\n",
    "\n",
    "print(f\"Processed {len(all_sections)} articles.\")\n",
    "print(\"Example (first article):\")\n",
    "for sec_title, sec_text in all_sections[0]['sections']:\n",
    "    print(f\"\\n--- {sec_title} ---\\n{sec_text[:200]} ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d74f1e",
   "metadata": {},
   "source": [
    "## 4. Summarization (Local T5 Model, GPU Accelerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b816a69bdb2545c4a1243731a66fea25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amira\\Downloads\\SlidegenAI\\SlidegenAI\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amira\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06649dfdcaeb4599a2f0e5f629362181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9e5ef176d5483dad49437fc07eff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce91749e7a24548be6fa0136a74f829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b341dfc24a64dc38d708600ed206bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dde7a20e6364c25bfeff7aae5e1f359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load the summarization model\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"t5-small\",   # change to your fine-tuned model if available\n",
    "    tokenizer=\"t5-small\",\n",
    "    device=0 if device==\"cuda\" else -1\n",
    ")\n",
    "\n",
    "def summarize_section(text, max_length=120, min_length=30):\n",
    "    \"\"\"\n",
    "    Summarize a section using T5.\n",
    "    \"\"\"\n",
    "    input_text = \"summarize: \" + text\n",
    "    summary = summarizer(\n",
    "        input_text,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        do_sample=False\n",
    "    )[0]['summary_text']\n",
    "    return summary\n",
    "\n",
    "# Summarize the first few sections for the demo\n",
    "summaries = []\n",
    "for section_title, section_text in sections[:4]:\n",
    "    print(f\"\\nSummarizing section: {section_title}\")\n",
    "    summary = summarize_section(section_text[:1500])  # Truncate for demo\n",
    "    summaries.append((section_title, summary))\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc62f2f",
   "metadata": {},
   "source": [
    "## 5. Slide Generation (PowerPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "357f1e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Presentation saved as: generated_presentation.pptx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_presentation(summaries, out_path=\"generated_presentation.pptx\"):\n",
    "    prs = Presentation()\n",
    "    title_slide_layout = prs.slide_layouts[0]\n",
    "    content_slide_layout = prs.slide_layouts[1]\n",
    "    \n",
    "    # Title Slide\n",
    "    slide = prs.slides.add_slide(title_slide_layout)\n",
    "    slide.shapes.title.text = \"Automated Slide Generation\"\n",
    "    slide.placeholders[1].text = \"Generated from arXiv Paper Using NLP\"\n",
    "    \n",
    "    # Content Slides\n",
    "    for section_title, summary in summaries:\n",
    "        slide = prs.slides.add_slide(content_slide_layout)\n",
    "        slide.shapes.title.text = section_title\n",
    "        tf = slide.placeholders[1].text_frame\n",
    "        # Split summary into bullet points if possible\n",
    "        bullets = summary.split('. ')\n",
    "        for bullet in bullets:\n",
    "            if bullet.strip():\n",
    "                tf.add_paragraph().text = bullet.strip() + ('.' if not bullet.strip().endswith('.') else '')\n",
    "        # Remove first empty paragraph\n",
    "        if tf.paragraphs and not tf.paragraphs[0].text.strip():\n",
    "            tf._element.remove(tf.paragraphs[0]._element)\n",
    "    prs.save(out_path)\n",
    "    print(f\"\\nPresentation saved as: {out_path}\")\n",
    "\n",
    "# Create the slides!\n",
    "create_presentation(summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e07192",
   "metadata": {},
   "source": [
    "## 6. Full Pipeline Function (Reusable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3729eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Presentation saved as: demo_presentation.pptx\n"
     ]
    }
   ],
   "source": [
    "def process_article(article_text, n_sections=4):\n",
    "    \"\"\"\n",
    "    Splits, summarizes, and returns sections for slide generation.\n",
    "    \"\"\"\n",
    "    sections = split_sections(article_text)\n",
    "    summaries = []\n",
    "    for section_title, section_text in sections[:n_sections]:\n",
    "        summary = summarize_section(section_text[:1500])\n",
    "        summaries.append((section_title, summary))\n",
    "    return summaries\n",
    "\n",
    "# Example: Full pipeline for the first article\n",
    "article_text = \" \".join(combined_samples[0]['article_text'])\n",
    "demo_summaries = process_article(article_text)\n",
    "create_presentation(demo_summaries, out_path=\"demo_presentation.pptx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6263b95",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b85aedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook pipeline complete! Ready for final project submission or demonstration.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - This notebook demonstrates a full offline pipeline for extracting, summarizing, and generating PowerPoint slides from research papers.\n",
    "# - It is ready for further customization, batch processing, and improvements.\n",
    "# - For best results, use a domain-specific or fine-tuned summarization model and enhance section splitting heuristics.\n",
    "# - You can easily expand this to process multiple articles, generate fancier slides, or add images from PDF extraction.\n",
    "# - Everything is designed to run offline after model download, and GPU acceleration is enabled.\n",
    "\n",
    "print(\"Notebook pipeline complete! Ready for final project submission or demonstration.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

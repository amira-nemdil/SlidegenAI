{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67d3fc4",
   "metadata": {},
   "source": [
    "# üßë‚Äçüéì SlideGenAI: Research-Grade Slide Generation with Flan-T5 (arXiv & PubMed)\n",
    "\n",
    "This notebook trains, validates, and evaluates a Flan-T5 model to generate slide-style summaries from scientific abstracts.  \n",
    "- **Datasets:** arXiv & PubMed (train/val/test sets)\n",
    "- **Framework:** PyTorch + HuggingFace\n",
    "- **Evaluation:** ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f2601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "MODEL_NAME = \"google/flan-t5-large\"  # or 'google/flan-t5-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2aba1f",
   "metadata": {},
   "source": [
    "# 1. üìö Data Loading (arXiv & PubMed)\n",
    "\n",
    "Both datasets must have `train.txt`, `val.txt`, `test.txt`, one JSON per line.  \n",
    "We load, filter, format, and cache them for fast repeated experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd64f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Path config: Set to your downloaded dataset folders ====\n",
    "ARXIV_DIR = r\"C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\arxiv-dataset\\arxiv-dataset\"\n",
    "PUBMED_DIR = r\"C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\pubmed-dataset\\pubmed-dataset\"\n",
    "\n",
    "def load_jsonl(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "# New universal filter for both datasets (since they have same structure)\n",
    "def filter_any(sample):\n",
    "    # Require non-empty article_text and at least 200 characters\n",
    "    return \"article_text\" in sample and len(sample[\"article_text\"]) > 0 and len(\" \".join(sample[\"article_text\"])) > 200\n",
    "\n",
    "def split_into_slides_from_list(article_text, n_slides=4):\n",
    "    # article_text is a list of sentences/paragraphs\n",
    "    sentences = article_text\n",
    "    chunk_size = len(sentences) // n_slides + 1\n",
    "    slides = [' '.join(sentences[i:i+chunk_size]).strip() for i in range(0, len(sentences), chunk_size)]\n",
    "    return [s for s in slides if s]\n",
    "\n",
    "def preprocess(samples, name):\n",
    "    processed = []\n",
    "    for sample in samples:\n",
    "        if filter_any(sample):\n",
    "            slides = split_into_slides_from_list(sample[\"article_text\"])\n",
    "            processed.append({\n",
    "                'title': sample.get('article_id', ''),  # use article_id as a unique \"title\"\n",
    "                'slides': slides,\n",
    "                'abstract': \" \".join(sample[\"article_text\"]),  # treat joined text as abstract\n",
    "            })\n",
    "    print(f\"{name}: {len(processed)} after filtering & formatting\")\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ed14af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\arxiv-dataset\\arxiv-dataset\\train.txt exists: True\n",
      "  203037 lines; first line: {\"article_id\": \"1405.3379\", \"article_text\": [\"additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive mo\n",
      "C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\arxiv-dataset\\arxiv-dataset\\val.txt exists: True\n",
      "  6436 lines; first line: {\"article_id\": \"0708.1996\", \"article_text\": [\"the interest in anchoring phenomena and phenomena in confined nematic liquid crystals has largely been driven by their potential use in liquid crystal dis\n",
      "C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\arxiv-dataset\\arxiv-dataset\\test.txt exists: True\n",
      "  6440 lines; first line: {\"article_id\": \"1009.3123\", \"article_text\": [\"for about 20 years the problem of properties of short - term changes of solar activity has been considered extensively .\", \"many investigators studied the\n",
      "C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\pubmed-dataset\\pubmed-dataset\\train.txt exists: True\n",
      "  119924 lines; first line: {\"article_id\": \"PMC3872579\", \"article_text\": [\"a recent systematic analysis showed that in 2011 , 314 ( 296 - 331 ) million children younger than 5 years were mildly , moderately or severely stunted a\n",
      "C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\pubmed-dataset\\pubmed-dataset\\val.txt exists: True\n",
      "  6633 lines; first line: {\"article_id\": \"PMC4810892\", \"article_text\": [\"approximately , one - third of patients with symptomatic vte manifests pe , whereas two - thirds manifest dvt alone .\", \"both dvt and pe can be clinicall\n",
      "C:\\Users\\amira\\Downloads\\datasets SlidegenAI\\pubmed-dataset\\pubmed-dataset\\test.txt exists: True\n",
      "  6658 lines; first line: {\"article_id\": \"PMC5075302\", \"article_text\": [\"anxiety affects quality of life in those living with parkinson 's disease ( pd ) more so than overall cognitive status , motor deficits , apathy , and de\n"
     ]
    }
   ],
   "source": [
    "for source, src_dir in [(\"arxiv\", ARXIV_DIR), (\"pubmed\", PUBMED_DIR)]:\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        src_path = os.path.join(src_dir, f\"{split}.txt\")\n",
    "        print(f\"{src_path} exists:\", os.path.exists(src_path))\n",
    "        if os.path.exists(src_path):\n",
    "            with open(src_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "                print(f\"  {len(lines)} lines; first line: {lines[0][:200] if lines else 'EMPTY'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa77ac",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Load, Filter, and Format All Splits (arXiv & PubMed)\n",
    "_Cached files will be used if present for fast reruns._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv train: Loaded 0 from cache.\n",
      "arxiv val: Loaded 0 from cache.\n",
      "arxiv test: Loaded 0 from cache.\n",
      "pubmed train: Loaded 0 from cache.\n",
      "pubmed val: Loaded 0 from cache.\n",
      "pubmed test: Loaded 0 from cache.\n",
      "Dataset sizes:\n",
      "arXiv train/val/test: [0, 0, 0]\n",
      "PubMed train/val/test: [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Where to save filtered data\n",
    "CACHE_DIR = \"./slidegen_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "def cached_load_or_preprocess(src_path, cache_path, name):\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "        print(f\"{name}: Loaded {len(data)} from cache.\")\n",
    "        return data\n",
    "    raw = load_jsonl(src_path)\n",
    "    data = preprocess(raw, name)\n",
    "    with open(cache_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "datasets = {}\n",
    "for source, src_dir in [(\"arxiv\", ARXIV_DIR), (\"pubmed\", PUBMED_DIR)]:\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        src_path = os.path.join(src_dir, f\"{split}.txt\")\n",
    "        cache_path = os.path.join(CACHE_DIR, f\"{source}_{split}_filtered.jsonl\")\n",
    "        datasets[f\"{source}_{split}\"] = cached_load_or_preprocess(\n",
    "            src_path, cache_path, f\"{source} {split}\"\n",
    "        )\n",
    "# Check the number of samples in each dataset\n",
    "print(\"Dataset sizes:\")\n",
    "print(\"arXiv train/val/test:\", [len(datasets[f\"arxiv_{s}\"]) for s in [\"train\", \"val\", \"test\"]])\n",
    "print(\"PubMed train/val/test:\", [len(datasets[f\"pubmed_{s}\"]) for s in [\"train\", \"val\", \"test\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec53a5",
   "metadata": {},
   "source": [
    "# 2. üîÑ Dataset Selection & Mixing\n",
    "\n",
    "Combine datasets for larger training, or use arXiv/PubMed only.  \n",
    "Edit below as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your training/validation/test sets here:\n",
    "train_data = datasets[\"arxiv_train\"] + datasets[\"pubmed_train\"]\n",
    "val_data   = datasets[\"arxiv_val\"] + datasets[\"pubmed_val\"]\n",
    "test_data  = datasets[\"arxiv_test\"] + datasets[\"pubmed_test\"]\n",
    "\n",
    "# To use only arXiv or only PubMed, set e.g.:\n",
    "# train_data = datasets[\"arxiv_train\"]\n",
    "# val_data = datasets[\"arxiv_val\"]\n",
    "# test_data = datasets[\"arxiv_test\"]\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee435b",
   "metadata": {},
   "source": [
    "# 3. ‚ú® Tokenization & Dataset Preparation\n",
    "\n",
    "We use the Flan-T5 tokenizer and wrap everything in a PyTorch Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fb5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "class SlidesDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input=512, max_target=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input = max_input\n",
    "        self.max_target = max_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        source = sample[\"abstract\"]\n",
    "        target = ' ; '.join(sample[\"slides\"])  # use ';' as slide separator\n",
    "        \n",
    "        model_inputs = self.tokenizer(\n",
    "            source, max_length=self.max_input, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "        )\n",
    "        labels = self.tokenizer(\n",
    "            target, max_length=self.max_target, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in model_inputs.items()}\n",
    "        item['labels'] = labels['input_ids'].squeeze(0)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5dd90c",
   "metadata": {},
   "source": [
    "## üî• DataLoader Setup\n",
    "Efficient batched loading for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2eb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = SlidesDataset(train_data, tokenizer, max_input_length, max_target_length)\n",
    "val_dataset   = SlidesDataset(val_data, tokenizer, max_input_length, max_target_length)\n",
    "test_dataset  = SlidesDataset(test_data, tokenizer, max_input_length, max_target_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbbb68",
   "metadata": {},
   "source": [
    "# 4. üèãÔ∏è‚Äç‚ôÇÔ∏è Model, Training & Validation Loops\n",
    "\n",
    "Train Flan-T5 with full GPU support and validation using ROUGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ed14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# Optimizer, scheduler\n",
    "EPOCHS = 3  # Increase for full training\n",
    "LEARNING_RATE = 3e-5\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=200, num_training_steps=total_steps)\n",
    "\n",
    "# --- Helper for ROUGE ---\n",
    "def compute_rouge_scores(preds, targets):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    all_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
    "    for pred, tgt in zip(preds, targets):\n",
    "        scores = scorer.score(tgt, pred)\n",
    "        for key in all_scores:\n",
    "            all_scores[key].append(scores[key].fmeasure)\n",
    "    return {k: float(np.mean(v)) if v else 0.0 for k, v in all_scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc38b7e",
   "metadata": {},
   "source": [
    "## üöÄ Training & Validation Loop\n",
    "Prints loss and ROUGE for every epoch.  \n",
    "Model is checkpointed on best validation ROUGE-L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def generate_slides(batch_abstracts, model, tokenizer, max_len=128):\n",
    "    inputs = tokenizer(batch_abstracts, return_tensors=\"pt\", max_length=512, truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=max_len,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def validate(model, val_loader, tokenizer):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            abstracts = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "            batch_preds = generate_slides(abstracts, model, tokenizer)\n",
    "            all_preds.extend(batch_preds)\n",
    "            # Targets: decode labels, strip padding and join if needed\n",
    "            for labels in batch[\"labels\"]:\n",
    "                label_text = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "                all_targets.append(label_text)\n",
    "    # ROUGE\n",
    "    rouge_scores = compute_rouge_scores(all_preds, all_targets)\n",
    "    return rouge_scores\n",
    "\n",
    "best_val_rougeL = 0.0\n",
    "model_ckpt_path = \"./flan_t5_slidegen_best.pth\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1}: Train loss: {train_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    rouge_scores = validate(model, val_loader, tokenizer)\n",
    "    print(f\"Validation ROUGE: {rouge_scores}\")\n",
    "    if rouge_scores[\"rougeL\"] > best_val_rougeL:\n",
    "        print(\"New best model! Saving checkpoint.\")\n",
    "        best_val_rougeL = rouge_scores[\"rougeL\"]\n",
    "        torch.save(model.state_dict(), model_ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57848fb5",
   "metadata": {},
   "source": [
    "# 5. üß™ Final Evaluation on Test Set\n",
    "\n",
    "Restore the best model and run on test set for final ROUGE reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c83143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore best checkpoint\n",
    "model.load_state_dict(torch.load(model_ckpt_path))\n",
    "model.eval()\n",
    "\n",
    "test_rouge = validate(model, test_loader, tokenizer)\n",
    "print(\"Final Test ROUGE:\", test_rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379f32e",
   "metadata": {},
   "source": [
    "# üéâ Results, Download, and Next Steps\n",
    "\n",
    "- Download your best model checkpoint: `flan_t5_slidegen_best.pth`\n",
    "- Results: Final ROUGE scores on test set (see above)\n",
    "- You can now deploy or export model for inference!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
